{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "10d250e1",
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "source": [
        "# 1. Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93d3c1e",
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "2"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26393ffa",
      "metadata": {},
      "source": [
        "# 2. Loading in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21ba1d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = Path(\"../Data/Raw/Uitgebreide_VKM_dataset.csv\")\n",
        "df = pd.read_csv(file_path, low_memory=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bee1d1ca",
      "metadata": {},
      "source": [
        "# 3. Overview dataset and data quality\n",
        "\n",
        "In this section we explore the structure, data types, and overall data quality of the dataset. We look at the shape, column types, missing values, and basic numeric statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e25388",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumns and dtypes:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Missing values\n",
        "miss = df.isnull().mean() * 100\n",
        "print(\"\\nMissing %:\")\n",
        "print(miss.sort_values(ascending=False))\n",
        "\n",
        "# Numeric summary\n",
        "num = df.select_dtypes(include=[np.number])\n",
        "print(\"\\nNumeric summary:\")\n",
        "print(num.describe().T)\n",
        "\n",
        "# Categorical summary for selected columns\n",
        "for col in ['name', 'shortdescription', 'description', 'content', 'location', 'level', 'learningoutcomes', 'module_tags', 'start_date']:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    vc = df[col].value_counts(dropna=False).head(10)\n",
        "    print(\"Top values:\\n\", vc)\n",
        "    print(\"Unique (non-null):\", df[col].nunique(dropna=True))\n",
        "\n",
        "# Date parsing for 'start_date' column\n",
        "parsed_dates = pd.to_datetime(df['start_date'], errors='coerce')\n",
        "print(\"\\nstart_date parsing:\")\n",
        "print(\"Nulls after parsing:\", parsed_dates.isna().sum())\n",
        "print(\"Top parsed dates:\")\n",
        "print(parsed_dates.value_counts().head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feca0051",
      "metadata": {},
      "source": [
        "What we found from this:\n",
        "- Most columns are of type \"Object\" containing textual data. This is also the sort of data most useful for a content-based recommender systen we plan making. \n",
        "- The color coded columns only have 2 rows containing data. Short descritpion and learning outcomes have some missing values we'll have to look into deeper during data cleaning.\n",
        "- Popularity Score goes from 10 to 500. Dificulty goes from 1 to 5. Interest scores seems to go from 0 to 1. This could all be normalized to a value from 0.1 for consistency...\n",
        "- There are some rows containing duplicate data --> Duplicates need to be removed during data cleaning.\n",
        "- Bepaalde tags zijn leeg of zijn gevuld met 'ntb'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8a1cb62",
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "source": [
        "# 4. Numeric Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d68d1e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "import html as _html\n",
        "\n",
        "num = df.select_dtypes(include=[np.number]).copy()\n",
        "summary = []\n",
        "\n",
        "for col in num.columns:\n",
        "    col_s = num[col].dropna()\n",
        "    mean = col_s.mean()\n",
        "    min_val = col_s.min() if len(col_s) > 0 else np.nan\n",
        "    max_val = col_s.max() if len(col_s) > 0 else np.nan\n",
        "\n",
        "    # Plots\n",
        "    if len(col_s) > 0:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
        "        sns.histplot(col_s, ax=axes[0], kde=True)\n",
        "        axes[0].set_title(f\"{col} — mean={mean:.2f}\")\n",
        "        sns.boxplot(x=col_s, ax=axes[1])\n",
        "        axes[1].set_title(f\"Boxplot (min={min_val:.2f}, max={max_val:.2f})\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee4a5e6",
      "metadata": {},
      "source": [
        "What we found (besides the findings already mentioned earlier):\n",
        "- Studycredit exists only in 15 or 30 points\n",
        "- One contactId stands out for the rest "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc74d309",
      "metadata": {},
      "source": [
        "# 5. Categorical Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5f1761",
      "metadata": {},
      "outputs": [],
      "source": [
        "# top-10 (or lower if not applicable) bar charts for categorical columns\n",
        "\n",
        "# Some categorical columns left out on purpose like shortdescription, description, etc. Not useful for bar charts. Name is used to find potential duplicates \n",
        "exclude_text_cols = ['shortdescription', 'description', 'content']\n",
        "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "cat_cols = [c for c in cat_cols if c not in exclude_text_cols]\n",
        "\n",
        "top_n = 10\n",
        "\n",
        "# Shorting x-axis description otherwise too long images.\n",
        "def _shorten(s, n=50):\n",
        "    s = str(s)\n",
        "    return s if len(s) <= n else s[:47] + '...'\n",
        "\n",
        "for col in cat_cols:\n",
        "    vc = df[col].fillna('<<NA>>').value_counts()\n",
        "    top10 = vc.head(top_n)\n",
        "    labels = [_shorten(x, 50) for x in top10.index]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 3))\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(top10)))\n",
        "\n",
        "    top10.plot(kind='bar', color=colors, ax=ax)\n",
        "    ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=9)\n",
        "    ax.set_title(f'{col} — top {len(top10)}')\n",
        "    ax.set_ylabel('count')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5725d634",
      "metadata": {},
      "source": [
        "What we found (besides the findings already mentioned earlier):\n",
        "- Duplicates in module name found, need to be removed during data cleanup\n",
        "- Some location values have 2 places mixed, better to seperate these and add them to both locations. --> making Location an array\n",
        "- Learningoutcomes have several columns with no information. Not only are there rows filled with NaN, but also rows with: 'nog te bepalen', 'nog te formuleren', etc. These will have to be cleaned. Also tricky value: 'Nog te bepalen. Bijvoorbeeld: bla bla bla....'. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9343465",
      "metadata": {},
      "source": [
        "# 6. Correlation heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72aa3b6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = df.corr(numeric_only=True)\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Draw the heatmap\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar_kws={\"shrink\": .8})\n",
        "\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06763b88",
      "metadata": {},
      "source": [
        "# 7. Text Analysis (content & description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b79922c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"exact_same\"] = df[\"content\"] == df[\"description\"]\n",
        "df[\"exact_same\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d9a7b75",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[~df[\"exact_same\"], [\"content\", \"description\", \"shortdescription\", \"module_tags\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff82f859",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------\n",
        "# Text cleaning function\n",
        "# --------------------------\n",
        "def normalize(text):\n",
        "    if text is None or (isinstance(text, float) and np.isnan(text)):\n",
        "        return \"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "# --------------------------\n",
        "# Load model\n",
        "# --------------------------\n",
        "print(\"Loading sentence transformer model...\")\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "# --------------------------\n",
        "# Function to compute similarity and visualize\n",
        "# --------------------------\n",
        "def explore_similarity(df, col1, col2, threshold=0.8):\n",
        "    print(\"Filling NaN values...\")\n",
        "    df[col1] = df[col1].fillna(\"\")\n",
        "    df[col2] = df[col2].fillna(\"\")\n",
        "    \n",
        "    # normalize\n",
        "    print(f\"Normalizing {col1} and {col2}...\")\n",
        "    df[f\"{col1}_norm\"] = df[col1].apply(normalize)\n",
        "    df[f\"{col2}_norm\"] = df[col2].apply(normalize)\n",
        "\n",
        "    # embeddings\n",
        "    print(\"Computing embeddings...\")\n",
        "    df[f\"{col1}_emb\"] = df[f\"{col1}_norm\"].apply(lambda x: model.encode(x))\n",
        "    df[f\"{col2}_emb\"] = df[f\"{col2}_norm\"].apply(lambda x: model.encode(x))\n",
        "\n",
        "    # cosine similarity\n",
        "    print(\"Calculating cosine similarity...\")\n",
        "    df[\"similarity\"] = df.apply(\n",
        "        lambda row: cosine_similarity([row[f\"{col1}_emb\"]], [row[f\"{col2}_emb\"]])[0][0],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # filter low similarity rows\n",
        "    low_sim = df[df[\"similarity\"] < threshold].copy()\n",
        "    display_cols = [col1, col2, \"similarity\"]\n",
        "    low_sim_display = low_sim[display_cols]\n",
        "\n",
        "    # simple coloring function\n",
        "    def highlight(val):\n",
        "        if val < 0.5:\n",
        "            return \"background-color: red\"\n",
        "        elif val < 0.7:\n",
        "            return \"background-color: orange\"\n",
        "        else:\n",
        "            return \"background-color: yellow\"\n",
        "\n",
        "    print(f\"Found {len(low_sim)} rows with similarity < {threshold}\")\n",
        "    return low_sim_display.style.applymap(highlight, subset=[\"similarity\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce5e442",
      "metadata": {},
      "outputs": [],
      "source": [
        "# compare content vs description\n",
        "explore_similarity(df, \"content\", \"description\", threshold=0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "623df18d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking if one of the columns is empty while the other is not\n",
        "empty_short = df[\"shortdescription\"].isna() | (df[\"shortdescription\"] == \"\")\n",
        "empty_tags = df[\"module_tags\"].isna() | (df[\"module_tags\"] == \"\")\n",
        "\n",
        "df[\"empty_or_mismatch\"] = empty_short | empty_tags\n",
        "print(\"Rows where one column is empty and the other is not:\")\n",
        "print(df[\"empty_or_mismatch\"].sum())\n",
        "\n",
        "explore_similarity(df, \"shortdescription\", \"module_tags\", threshold=0.99)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cddb25",
      "metadata": {},
      "source": [
        "We analyzed the similarity between different text columns in the dataset, focusing on content versus description and shortdescription versus module_tags. When we compared content and description, we found 11 rows with a cosine similarity below 0.8, which showed me that some module content didn’t really reflect their full descriptions. The lowest similarities were for modules like Oncologie (0.296) and Teaching English Abroad (0.219), which told me the titles were quite different from the content. For shortdescription versus module_tags, we noticed 6 rows with similarity below 0.88, which made me realize that some short descriptions or tags didn’t fully match the modules. Overall, most rows had decent similarity, but a few stood out as needing attention, so we know where we might want to refine or standardize the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6863a0c7",
      "metadata": {},
      "source": [
        "## Additional Findings\n",
        "\n",
        "- The dataset contains essentially no meaningful numerical relationships internally.  \n",
        "- The high correlation between `ID` and `Contact-ID` can be ignored, as it has no practical significance.  \n",
        "- Color values are not useful and can be disregarded.  \n",
        "- **Shortdescription vs. module_tags similarity**  \n",
        "  - Most rows show high similarity.  \n",
        "  - A few outliers indicate where refinement or standardization may be needed.  \n",
        "  - Not all modules have `shortdescription` filled in, so this field will likely be dropped during data cleaning.  \n",
        "- **Content vs. description similarity**  \n",
        "  - Most rows show high similarity, with some outliers needing review.  \n",
        "  - Specific modules may require refinement of `content` or `description`.  \n",
        "  - Ultimately, the `content` field will likely be dropped as it is inconsistently filled.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b661175a",
      "metadata": {},
      "source": [
        "# 7. Thoughts for final model\n",
        "Based on our exploration of the dataset, we cannot build a traditional prediction (classification) model. The available features show no significant correlations with the target variable (title or id), making it impossible to predict using standard methods. This is further complicated by the fact that most of the data is text. Additionally, the target itself represents content, which is not easily predicted using standard regression or classification techniques.\n",
        "\n",
        "Because of this, a recommendation system is a much more suitable solution. Instead of predicting a specific value, a recommender focuses on similarity between items or user preferences, which matches the structure of our dataset.\n",
        "\n",
        "Therefore, we will proceed with building a Content-Based Recommender system, which leverages the textual features of the dataset to recommend similar items based on their content. We will utilize techniques such as TF-IDF vectorization, embedding, and cosine similarity to measure the similarity between user profiles and the items in the dataset. This approach allows us to provide personalized recommendations without relying on traditional predictive modeling.\n",
        "\n",
        "But first, we are going to clean the dataset. This is done in the next notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
