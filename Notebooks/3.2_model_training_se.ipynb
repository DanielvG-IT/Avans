{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332653ab",
   "metadata": {},
   "source": [
    "# Model Training Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121055a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddc36cc5e3d48a8af6f1a7421eb3148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\woute\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367ca7f6f08249b9b1a81bc82b3e0e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bcb4902d394d09ad7732ba1a2ac988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77104ae3390d4db8b7a91756199bee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e970212ef84612a8ddb9cb1d28e7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6246020279b442668b02fafce956da29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84274255494f47378dbbf9a079120ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e2480d09ae4ea2b21084f13d9a6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28caa06505427ca01213d1115d623e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b071717cefee4a2699909dbf82a79d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87dc9ba6674409b928b3debb4809d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers.functs.StudentProfile import StudentProfile\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "\n",
    "# Loading sentence model\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../Data/Cleaned/cleaned_dataset_hard-NLP.csv')\n",
    "\n",
    "# Loading uncleaned dataset for feedback names, etc. that have not seen NLP for user friendliness\n",
    "raw_df = pd.read_csv('../Data/Raw/Uitgebreide_VKM_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30988a73",
   "metadata": {},
   "source": [
    "Some of the first steps of preparing the data will be the same as we did in the training of the BOW model. This is why we won't explain all those steps again in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41ed59",
   "metadata": {},
   "source": [
    "## 0. Mocking a student profile (Copy of 3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103119a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = StudentProfile(\n",
    "    current_study= \"Kunst & Onderzoek\",\n",
    "    interests=[\n",
    "        \"Tekening\",\n",
    "        \"Animatie\",\n",
    "        \"Kunst\",\n",
    "        \"Artistiek\",\n",
    "        \"Het vermaken van mensen. Via zingen, dansen, toneel. Graag op het podium. \"\n",
    "    ],\n",
    "    wanted_study_credit_range=(15, 30),\n",
    "    location_preference=[\"Den Bosch\", \"Breda\", \"Tilburg\"],\n",
    "    learning_goals=[\"CarriÃ¨re groei\", \"Sociale vaardigheden\", \"Zelfverzekerheid\", \"Vermaken\"],\n",
    "    level_preference=[\"NLQF5\", \"NLQF6\"],\n",
    "    preferred_language=\"NL\",\n",
    ")\n",
    "\n",
    "matching_models = [388, 392, 191, 385, 386, 379, 389, 377, 233]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8bbdf4",
   "metadata": {},
   "source": [
    "Creating a filtered dataset. Copy of the dataset used for comparison later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebe3736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of modules: 211\n",
      "Number of modules after filtering: 211\n"
     ]
    }
   ],
   "source": [
    "# Create filtered module and save. The filtered one won't be used by TF-IDF because that would create bias. (Smaller amount of modules compared > easier higher scores)\n",
    "filtered_df = df.copy()\n",
    "\n",
    "# Helper to normalize the list-like location strings such as \"['Den Bosch', 'Tilburg']\"\n",
    "def normalize_locations(series):\n",
    "    def _to_list(val):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(str(val))\n",
    "            if isinstance(parsed, list):\n",
    "                return [str(x).strip().lower() for x in parsed]\n",
    "            return [str(parsed).strip().lower()]\n",
    "        except Exception:\n",
    "            return [str(val).strip().lower()]\n",
    "    return series.apply(_to_list)\n",
    "\n",
    "# --- 1. Study credits range ---\n",
    "if hasattr(student, \"wanted_study_credit_range\") and student.wanted_study_credit_range is not None:\n",
    "    min_cred, max_cred = student.wanted_study_credit_range\n",
    "    filtered_df = filtered_df[(filtered_df[\"studycredit\"] >= min_cred) & (filtered_df[\"studycredit\"] <= max_cred)]\n",
    "\n",
    "# --- 2. Location preference ---\n",
    "if hasattr(student, \"location_preference\") and student.location_preference:\n",
    "    all_locs_filtered = normalize_locations(filtered_df[\"location\"])\n",
    "    loc_prefs_norm = [str(x).strip().lower() for x in student.location_preference]\n",
    "    loc_mask = all_locs_filtered.apply(lambda lst: any(x in loc_prefs_norm for x in lst))\n",
    "    filtered_df = filtered_df[loc_mask]\n",
    "\n",
    "# --- 3. Language of the module vs preferred language of the student ---\n",
    "# Pretty complicated to include and won't be of any use anyways since tf-idf won't be able to link interests written in difference language than de modules\n",
    "\n",
    "# --- 4. Level preference (e.g. NLQF levels) ---\n",
    "if hasattr(student, \"level_preference\") and student.level_preference:\n",
    "    level_prefs = [str(x).strip().lower() for x in student.level_preference]\n",
    "    filtered_df = filtered_df[filtered_df[\"level\"].astype(str).str.lower().isin(level_prefs)]\n",
    "\n",
    "# --- 5. Availability > 0 ---\n",
    "filtered_df = filtered_df[filtered_df[\"available_spots\"] > 0]\n",
    "\n",
    "print(f\"Original number of modules: {len(df)}\")\n",
    "print(f\"Number of modules after filtering: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8be4a",
   "metadata": {},
   "source": [
    "# 1. Combining Relevant Text Columns of Modules Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7a7367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159</td>\n",
       "      <td>kennismak psychologi modul ler gedrag jezelf a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160</td>\n",
       "      <td>learn work abroad student kiez binn stam oplei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161</td>\n",
       "      <td>proactiev zorgplann jeroen bosch ziekenhuis gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>rouw verlies modul stil gestan rouw verlies va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163</td>\n",
       "      <td>acuut complex zorg modul student verdiep acut ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text\n",
       "0  159  kennismak psychologi modul ler gedrag jezelf a...\n",
       "1  160  learn work abroad student kiez binn stam oplei...\n",
       "2  161  proactiev zorgplann jeroen bosch ziekenhuis gr...\n",
       "3  162  rouw verlies modul stil gestan rouw verlies va...\n",
       "4  163  acuut complex zorg modul student verdiep acut ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine relevant text columns \n",
    "big_string = (\n",
    "    df[\"name\"].fillna(\"\") + \" \" +\n",
    "    df[\"description\"].fillna(\"\") + \" \" +\n",
    "    df[\"learningoutcomes\"].fillna(\"\") + \" \" +\n",
    "    df[\"module_tags\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
    ")\n",
    "\n",
    "big_df = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"text\": big_string\n",
    "})\n",
    "\n",
    "big_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8154b",
   "metadata": {},
   "source": [
    "## 2. Vectorizing dataset\n",
    "This time we'll be using sentence embedding for our vectorization. We chose x because it will be able to work with a combination of both Dutch and English inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc75112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202305e01a14b208ec4a2dc5097b9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(211, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Encode big_df text with sentence embeddings\n",
    "big_df_embeddings = model.encode(big_df[\"text\"].tolist(), show_progress_bar=True)\n",
    "big_df_embeddings = np.array(big_df_embeddings)\n",
    "big_df_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
