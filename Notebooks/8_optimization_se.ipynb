{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82bbb978",
      "metadata": {},
      "source": [
        "# Embedding Optimization\n",
        "We will apply embedding optimization techniques to improve the quality of our embeddings for better recommendation performance. While creating the model we had a lot of options to choose from. Here we will explore some of those options and see how they affect the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "ef744b04",
      "metadata": {},
      "outputs": [],
      "source": [
        "from helpers.notebook_pipelines.yes_tuned_bow_model import run_evaluation_multi\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from helpers.functs.StudentProfile import StudentProfile\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import Iterable, Set, Tuple, List\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "9117afd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Our mocked student profiles\n",
        "student1 = StudentProfile(\n",
        "    current_study= \"Kunst & Onderzoek\",\n",
        "    interests=[\n",
        "        \"Tekenen\",\n",
        "        \"Animatie\",\n",
        "        \"Kunst\",\n",
        "        \"Drama\",\n",
        "        \"Ik hou ervan om mensen te vermaken. Dit doe ik het liefst door bijvoorbeeld te dansen, te zingen of toneelspelen. In het algemeen vind ik het fijn om creatief bezig te zijn. Ik ben graag onder de mensen.\"\n",
        "    ],\n",
        "    wanted_study_credit_range=(15, 30),\n",
        "    location_preference=[\"Den Bosch\", \"Breda\", \"Tilburg\"],\n",
        "    learning_goals=[\"Kritisch denken\", \"Sociale vaardigheden\", \"Zelfverzekerdheid\", \"Ik wil o.a. leren hoe ik betere illustraties kan maken zowel analoog als digitaal.\"],\n",
        "    level_preference=[\"NLQF5\", \"NLQF6\"],\n",
        "    preferred_language=\"NL\",\n",
        "    preferred_start_range=\"any\"\n",
        ")\n",
        "student2 = StudentProfile(\n",
        "    current_study= \"Informatica\",\n",
        "    interests=[\n",
        "        \"Programmeren\",\n",
        "        \"AI\",\n",
        "        \"Coderen\",\n",
        "        \"Techniek\",\n",
        "        \"Software\",\n",
        "        \"Ik heb werken met computers en techniek van jongs af aan al interessant gevonden. Kunstmatige intelligentie is nu ook zeker iets dat me interesseert, zeker met de sterke opkomst hiervan. Zo kun je denken aan machine learning, deep learning, etc. Ik wil me vooral bezighouden met software.\"\n",
        "    ],\n",
        "    wanted_study_credit_range=(15, 30),\n",
        "    location_preference=[\"Den Bosch\", \"Breda\", \"Tilburg\"],\n",
        "    learning_goals=[\"Kritisch denken\", \"Technische Vaardigheden\", \"EÃ©n van de dingen die ik wil leren is het toepassen van mijn kennis in de praktijk\"],\n",
        "    level_preference=[\"NLQF5\", \"NLQF6\"],\n",
        "    preferred_language=\"NL\",\n",
        "    preferred_start_range=\"any\"\n",
        ")\n",
        "student3 = StudentProfile(\n",
        "    current_study= \"Psychologie\",\n",
        "    interests=[\n",
        "        \"Mensen\",\n",
        "        \"Emoties\",\n",
        "        \"Gedrag\",\n",
        "        \"Psychologie\",\n",
        "        \"Ik wil graag weten waarom mensen bepaalde dingen doen; ik wil mensen hun gedrag kunnen begrijpen. Naast hun gedrag wil ik ook leren over, persoonlijkheden en emoties. Graag wil ik mensen hun welzijn kunnen bevorderen met het gebruik van psychologische kennis.\"\n",
        "    ],\n",
        "    wanted_study_credit_range=(15, 30),\n",
        "    location_preference=[\"Den Bosch\", \"Breda\", \"Tilburg\"],\n",
        "    learning_goals=[\"Kritisch denken\", \"Sociale Vaardigheden\", \"Ik wil leren hoe ik mensen en hun gedrag beter kan analyseren\"],\n",
        "    level_preference=[\"NLQF5\", \"NLQF6\"],\n",
        "    preferred_language=\"NL\",\n",
        "    preferred_start_range=\"any\"\n",
        ")\n",
        "students = [student1, student2, student3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d609bcbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "softNLP_df = pd.read_csv(\"../Data/Cleaned/cleaned_dataset_soft-NLP.csv\")\n",
        "hardNLP_df = pd.read_csv(\"../Data/Cleaned/cleaned_dataset_hard-NLP.csv\")\n",
        "\n",
        "# safely join selected columns into text (handle NaNs and non-str types)\n",
        "cols = ['name', 'description', 'learningoutcomes', 'module_tags']\n",
        "\n",
        "softNLP_module_text = (\n",
        "    softNLP_df[cols]\n",
        "    .fillna('')\n",
        "    .astype(str)\n",
        "    .agg(' '.join, axis=1)\n",
        "    .str.replace(r'\\s+', ' ', regex=True)\n",
        "    .tolist()\n",
        ")\n",
        "# use the dataset 'id' column so we report the real module ids (not dataframe positional indices)\n",
        "soft_module_ids = softNLP_df['id'].tolist()\n",
        "\n",
        "hardNLP_module_text = (\n",
        "    hardNLP_df[cols]\n",
        "    .fillna('')\n",
        "    .astype(str)\n",
        "    .agg(' '.join, axis=1)\n",
        "    .str.replace(r'\\s+', ' ', regex=True)\n",
        "    .tolist()\n",
        ")\n",
        "hard_module_ids = hardNLP_df['id'].tolist()\n",
        "\n",
        "# keep texts and their original ids together so we compute top-k per corpus\n",
        "nlp_options = {\n",
        "    \"soft\": (softNLP_module_text, soft_module_ids),\n",
        "    \"hard\": (hardNLP_module_text, hard_module_ids)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "b05fd5c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_options = {\n",
        "    \"Model1\": SentenceTransformer(\"all-MiniLM-L6-v2\"),\n",
        "    \"Model2\": SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\"),\n",
        "    \"Model3\": SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "281d40f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_k = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b7efc5",
      "metadata": {},
      "source": [
        "## Variations\n",
        "We will create several variations of our embedding models by changing parameters such as:\n",
        "- Model architecture\n",
        "- Preprocessing techniques\n",
        "- Fine-tuning strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "5dd26945",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "for s_idx, student in enumerate(students, start=1):\n",
        "    query_text = student.to_text()  # cleaned student text\n",
        "\n",
        "    results[f\"student{s_idx}\"] = {}\n",
        "\n",
        "    for nlp_name, (module_texts, module_ids) in nlp_options.items():\n",
        "        results[f\"student{s_idx}\"][nlp_name] = {}\n",
        "\n",
        "        for model_name, model in model_options.items():\n",
        "            # Encode modules\n",
        "            module_vectors = model.encode(module_texts, convert_to_tensor=True, device='cpu') # Use GPU if available\n",
        "            # Encode student profile\n",
        "            query_vector = model.encode([query_text], convert_to_tensor=True, device='cpu') # Use GPU if available\n",
        "            # Cosine similarity\n",
        "            scores = util.cos_sim(query_vector, module_vectors)[0].cpu().numpy()\n",
        "            # Get top-k matches (map positional indices back to original module ids)\n",
        "            top_indices = scores.argsort()[::-1][:top_k]\n",
        "            top_matches = [(module_ids[i], float(scores[i])) for i in top_indices]  # module_ids map to original dataframe index\n",
        "            results[f\"student{s_idx}\"][nlp_name][model_name] = top_matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "9543dd2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Student1 =====\n",
            "\n",
            "-- soft --\n",
            "Model1: [(32, 0.6879175901412964), (204, 0.6761541366577148), (205, 0.6016901731491089), (61, 0.6006748676300049), (199, 0.5994069576263428)]\n",
            "Model2: [(32, 0.7134238481521606), (188, 0.6478080749511719), (201, 0.6065809726715088), (192, 0.6056426763534546), (204, 0.6036763191223145)]\n",
            "Model3: [(32, 0.5802501440048218), (61, 0.46715906262397766), (204, 0.4508151710033417), (190, 0.440643310546875), (200, 0.3975970149040222)]\n",
            "\n",
            "-- hard --\n",
            "Model1: [(205, 0.5892462730407715), (204, 0.5761686563491821), (32, 0.5637335777282715), (206, 0.5525189638137817), (192, 0.5389763116836548)]\n",
            "Model2: [(202, 0.6092264652252197), (204, 0.5959000587463379), (192, 0.5894416570663452), (199, 0.5555411577224731), (61, 0.5532780885696411)]\n",
            "Model3: [(32, 0.4434344172477722), (204, 0.4381777346134186), (202, 0.3870798349380493), (190, 0.38502469658851624), (192, 0.3626526892185211)]\n",
            "\n",
            "===== Student2 =====\n",
            "\n",
            "-- soft --\n",
            "Model1: [(146, 0.7170849442481995), (179, 0.6960562467575073), (153, 0.6693323254585266), (54, 0.6630125045776367), (12, 0.6584594249725342)]\n",
            "Model2: [(153, 0.6933192014694214), (192, 0.6816544532775879), (121, 0.6539170742034912), (147, 0.6459530591964722), (130, 0.6420714259147644)]\n",
            "Model3: [(131, 0.5218096971511841), (146, 0.5045144557952881), (122, 0.4615938067436218), (192, 0.4497501850128174), (147, 0.4261051416397095)]\n",
            "\n",
            "-- hard --\n",
            "Model1: [(12, 0.5970869660377502), (136, 0.5893521308898926), (179, 0.5797098875045776), (146, 0.5664007663726807), (153, 0.5587651133537292)]\n",
            "Model2: [(146, 0.6507279872894287), (153, 0.5607253909111023), (122, 0.5527482032775879), (17, 0.5370391011238098), (121, 0.5344099998474121)]\n",
            "Model3: [(146, 0.5197422504425049), (131, 0.42505374550819397), (118, 0.4094988703727722), (122, 0.3976958096027374), (133, 0.37978386878967285)]\n",
            "\n",
            "===== Student3 =====\n",
            "\n",
            "-- soft --\n",
            "Model1: [(0, 0.6416774392127991), (14, 0.5865804553031921), (38, 0.5636337399482727), (204, 0.5565292835235596), (48, 0.5361244678497314)]\n",
            "Model2: [(0, 0.694542407989502), (24, 0.4558475911617279), (103, 0.43922895193099976), (205, 0.4280766248703003), (23, 0.42756974697113037)]\n",
            "Model3: [(0, 0.6357395648956299), (195, 0.4583189785480499), (18, 0.4361562728881836), (48, 0.4230063557624817), (170, 0.4167104661464691)]\n",
            "\n",
            "-- hard --\n",
            "Model1: [(0, 0.5801773071289062), (38, 0.502920925617218), (210, 0.49173057079315186), (204, 0.4634590744972229), (14, 0.4552552103996277)]\n",
            "Model2: [(0, 0.5793041586875916), (18, 0.5198308825492859), (103, 0.5032029151916504), (210, 0.4508299231529236), (48, 0.4287656545639038)]\n",
            "Model3: [(0, 0.5911657214164734), (195, 0.4098295271396637), (103, 0.4065195322036743), (48, 0.40191563963890076), (170, 0.39121344685554504)]\n"
          ]
        }
      ],
      "source": [
        "for student_name, student_results in results.items():\n",
        "    print(f\"\\n===== {student_name} =====\")\n",
        "    for nlp_name, nlp_results in student_results.items():\n",
        "        print(f\"\\n-- {nlp_name} --\")\n",
        "        for model_name, matches in nlp_results.items():\n",
        "            print(f\"{model_name}: {matches}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f9ab4f5",
      "metadata": {},
      "source": [
        "## presision@k Evaluation\n",
        "We will evaluate the performance of each variation using precision@k metric to determine which configuration yields the best results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "32900d8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ground-truth relevant modules per student\n",
        "ground_truth = {\n",
        "    \"student1\": [388, 392, 191, 385, 386, 379, 389, 377, 391, 233],\n",
        "    \"student2\": [304, 305, 312, 317, 318, 322, 321, 334, 336, 340, 333],\n",
        "    \"student3\": [159, 290, 397, 180, 177, 208, 173, 193, 357]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "90968f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Student1 =====\n",
            "\n",
            "-- SOFT NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n",
            "\n",
            "-- HARD NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n",
            "\n",
            "===== Student2 =====\n",
            "\n",
            "-- SOFT NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n",
            "\n",
            "-- HARD NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n",
            "\n",
            "===== Student3 =====\n",
            "\n",
            "-- SOFT NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n",
            "\n",
            "-- HARD NLP --\n",
            "Model1: Precision@5 = 0.00\n",
            "Model2: Precision@5 = 0.00\n",
            "Model3: Precision@5 = 0.00\n"
          ]
        }
      ],
      "source": [
        "def precision_at_k(top_matches, k, relevant_set):\n",
        "    \"\"\"\n",
        "    top_matches: list of (index, score)\n",
        "    relevant_set: set of ground truth module indices\n",
        "    \"\"\"\n",
        "    top_indices = [idx for idx, _ in top_matches[:k]]\n",
        "    relevant_in_top_k = sum(1 for idx in top_indices if idx in relevant_set)\n",
        "    return relevant_in_top_k / k\n",
        "\n",
        "# Compute Precision@k for all students\n",
        "precision_results = {}\n",
        "\n",
        "for student_name, student_results in results.items():\n",
        "    precision_results[student_name] = {}\n",
        "    for nlp_name, module_results in student_results.items():\n",
        "        precision_results[student_name][nlp_name] = {}\n",
        "        for model_name, top_matches in module_results.items():\n",
        "            # ground_truth keys use lowercase (e.g. 'student1') while results use 'Student1'\n",
        "            gt_key = student_name.lower() if student_name.lower() in ground_truth else student_name\n",
        "            relevant_set = set(ground_truth.get(gt_key, []))\n",
        "            precision = precision_at_k(top_matches, top_k, relevant_set)\n",
        "            precision_results[student_name][nlp_name][model_name] = precision\n",
        "\n",
        "# Display\n",
        "for student_name, student_precisions in precision_results.items():\n",
        "    print(f\"\\n===== {student_name} =====\")\n",
        "    for corpus_name, corpus_precisions in student_precisions.items():\n",
        "        print(f\"\\n-- {corpus_name.upper()} NLP --\")\n",
        "        for model_name, prec in corpus_precisions.items():\n",
        "            print(f\"{model_name}: Precision@{top_k} = {prec:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
